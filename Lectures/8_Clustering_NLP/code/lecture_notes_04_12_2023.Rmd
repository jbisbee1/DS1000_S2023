---
title: "Lecture Notes"
author: "Prof. Bisbee, Vanderbilt University"
date: "2023-04-12"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Log-Odds

```{r}
require(tidyverse)
require(tidytext)
require(scales)
tweet_words <- readRDS(file="../data/Trump_tweet_words.Rds") %>% # Note you can add data manipulations directly to the code that opens the file!
  mutate(PostPresident = Tweeting.date > "2016-11-03")

# Odds: Step 1 - Calculating word frequencies per period
odds1 <- tweet_words %>%
  count(word,PostPresident) %>% # word frequency by period
  group_by(word) %>%
  filter(sum(n) > 5) %>% # Dropping infrequently appearing words
  spread(PostPresident,n,fill = 0) %>%
  ungroup() %>%
  mutate(totFALSE = sum(`FALSE`),
         totTRUE = sum(`TRUE`))

# Odds: Step 2 - Tranforming frequencies into probabilities
odds2 <- odds1 %>%
  mutate(propFALSE = (`FALSE` + 1) / (totFALSE + 1),
         propTRUE = (`TRUE` + 1) / (totTRUE + 1))

# Odds: Step 3 - Divide proportion TRUE by proportion FALSE
odds3 <- odds2 %>%
  mutate(odds = propTRUE / propFALSE)

# Why log?
odds3 %>%
  ggplot(aes(x = odds)) + 
  geom_histogram() + 
  scale_x_log10()

# Ergo, log it
prepost_logodds <- odds3 %>%
  mutate(logodds = log(odds))
```

# Let's describe the log odds

```{r}
prepost_logodds %>%
  # mutate(prepost_odds = ifelse(logodds > 0,'Post','Pre'))
  group_by(logodds > 0) %>% # group by whether the word is more associated with pre or post
  top_n(15,abs(logodds)) %>%
  ungroup() %>%
  ggplot(aes(x = logodds,y = reorder(word,logodds),fill = logodds < 0)) + 
  geom_bar(stat = 'identity')
```


# Sentiment

```{r}
require(tidytext)

nrc <- get_sentiments('nrc')

nrc <- read_rds('https://github.com/jbisbee1/DS1000_S2023/blob/main/Lectures/8_Clustering_NLP/data/nrc.Rds?raw=true')

nrc %>%
  select(sentiment) %>%
  distinct()

nrc %>%
  count(sentiment)

# Proportion of words by sentiment pre/post presidency
word_freq <- tweet_words %>%
  group_by(PostPresident) %>%
  count(word) %>%
  filter(sum(n) >= 5) %>%
  mutate(prop = prop.table(n)) # Faster code / simpler code for calculating propotrions

# Attach sentiment 
word_freq_sent <- word_freq %>%
  inner_join(nrc,by = 'word')

word_freq_sent %>%
  group_by(sentiment) %>%
  top_n(10,n) %>%
  ungroup() %>%
  ggplot(aes(x = n,y = word)) + 
  geom_bar(stat = 'identity') + 
  facet_wrap(~sentiment,scales = 'free',nrow = 3)

# Using sentiment for descriptive analysis
tweet_sentiment <- tweet_words %>%
  inner_join(nrc,by = 'word')

# sentiment by presidency
tweet_sentiment_summary <- tweet_sentiment %>%
  group_by(PostPresident,sentiment) %>%
  count(document,sentiment) %>%
  ungroup() %>%
  arrange(document) %>%
  spread(sentiment,n,fill = 0) %>%
  mutate(net_sentiment = positive - negative)

# Is Trump happier before becoming president?
tweet_sentiment_summary %>%
  group_by(PostPresident) %>%
  mutate(nTweet = 1) %>%
  summarise(across(-document,sum)) # Fast way to calculate a bunch of columns

# Univariate visualization
tweet_sentiment_summary %>%
  ggplot(aes(x = net_sentiment,y = PostPresident)) + 
  geom_boxplot()

```